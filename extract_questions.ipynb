{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [This is the code for extracting questions from textbooks using mathpix and pypdf2](#toc1_)    \n",
    "- [Extract Questions from Linear Algebra Done Right](#toc2_)    \n",
    "- [Calculus Textbook](#toc3_)    \n",
    "  - [Attempt 1 to get questions](#toc3_1_)    \n",
    "  - [Attempt 2](#toc3_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[This is the code for extracting questions from textbooks using mathpix and pypdf2](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "import io\n",
    "import pandas as pd\n",
    "from mathpix_creds import HEADERS\n",
    "\n",
    "def extract_pages_and_process(pdf_path, start_page, end_page):\n",
    "    # Don't need to define poppler_path if it's already in PATH\n",
    "    pages =  convert_from_path(pdf_path, dpi=300, first_page=start_page, last_page=end_page) # poppler_path=r'C:\\Program Files\\poppler-23.10.0\\Library\\bin'\n",
    "    \n",
    "    all_text = \"\"\n",
    "    for i, page in enumerate(pages):\n",
    "        # Convert image to in-memory binary stream\n",
    "        buffer = io.BytesIO()\n",
    "        page.save(buffer, format=\"JPEG\")\n",
    "        buffer.seek(0)\n",
    "        \n",
    "        # Send the image to Mathpix OCR API\n",
    "        r = requests.post(\"https://api.mathpix.com/v3/text\",\n",
    "                          files={\"file\": buffer},\n",
    "                          data={\n",
    "                              \"options_json\": json.dumps({\n",
    "                                  \"math_inline_delimiters\": [\"$\", \"$\"],\n",
    "                                  \"rm_spaces\": True,\n",
    "                                  \"formats\":'text',\n",
    "                                  'numbers_default_to_math':True\n",
    "                                  # \"data_options\":{\n",
    "                                  #      #'include_svg':True,\n",
    "                                  #     #'include_mathml':True,\n",
    "                                  #     #'include_latex':True,\n",
    "                                  #     'include_asciimath':True\n",
    "                                  #     }\n",
    "                              })\n",
    "                          },\n",
    "                          headers=HEADERS)\n",
    "        data = r.json()\n",
    "        all_text += data['text'] +\"\\n\"\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_outline(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_content = file.read()\n",
    "    reader = PyPDF2.PdfReader(io.BytesIO(pdf_content))\n",
    "    outlines = reader.outline\n",
    "    return list(extract_items_from_outlines(outlines, reader))\n",
    "\n",
    "def extract_items_from_outlines(outlines, reader):\n",
    "    for item in outlines:\n",
    "        if isinstance(item, list):\n",
    "            # Recursive call for nested items\n",
    "            yield from extract_items_from_outlines(item, reader)\n",
    "        else:\n",
    "            yield item, reader\n",
    "def get_page_number(reader, page_obj):\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        if page == page_obj:\n",
    "            return i + 1  # '+ 1' to get 1-based page numbering\n",
    "    return None  # return None if page not found\n",
    "\n",
    "\n",
    "def get_questions(data_text):\n",
    "    questions = []\n",
    "    current_question = []\n",
    "    \n",
    "    for line in data_text.split('\\n'):\n",
    "        if re.match(r\"^\\$\\d+\\$\", line):  # Check if the line starts with a pattern like \"$1$\"\n",
    "            if current_question:  # If there's a current question, append it to the questions list\n",
    "                questions.append(\"\\n\".join(current_question))\n",
    "                current_question = []  # Reset the current question\n",
    "        current_question.append(line)\n",
    "    \n",
    "    # Add the last question if there's any\n",
    "    if current_question:\n",
    "        questions.append(\" \".join(current_question))\n",
    "        \n",
    "    # start_index = 0\n",
    "    # for i in range(len(questions)):\n",
    "    #     if re.match(\".*EXERCISES\\s+\\d+\\.[A-Z]\",questions[i]):\n",
    "    #         exercise_section = re.findall(\"EXERCISES\\s+(\\d+\\.[A-Z])\", questions[i])[0]\n",
    "    #         start_index = i+1\n",
    "    #     #questions[i] = questions[i].replace('\\n',\" \")\n",
    "    #     re.findall(r\"^\\$\\d+\\$\", questions[i])\n",
    "    return questions\n",
    "\n",
    "def to_frame(data,start_page):\n",
    "    exercise_section = None\n",
    "    start_index = 0\n",
    "    for index,line in enumerate(data):\n",
    "        match = re.search(r\"EXERCISES\\s+(\\d+\\.[A-Z])\", line)\n",
    "        if match:\n",
    "            exercise_section = match.group(1)\n",
    "            start_index = index+1\n",
    "    if exercise_section is None:\n",
    "        for index,line in enumerate(data):\n",
    "            match = re.search(r\"EXERCISES\\s+(\\$?\\d+(\\.\\w)?\\$?)\", line)\n",
    "            if match:\n",
    "                exercise_section = match.group(1).replace('$', '') \n",
    "                start_index = index+1\n",
    "    if not exercise_section:\n",
    "        raise ValueError(\"Exercise section not found in data!\")\n",
    "\n",
    "    # Extracting questions\n",
    "    questions = []\n",
    "    question_number = None\n",
    "\n",
    "\n",
    "    for idx, line in enumerate(data[start_index:]):\n",
    "        \n",
    "        match = re.match(r\"^\\$(\\d+)\\$\", line)  # Check if the line starts with a pattern like \"$1$\"\n",
    "        if match:\n",
    "\n",
    "            question_number = match.group(1)\n",
    "            questions.append({\n",
    "                \"page\": start_page,\n",
    "def extract_outline(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_content = file.read()\n",
    "    reader = PyPDF2.PdfReader(io.BytesIO(pdf_content))\n",
    "    outlines = reader.outline\n",
    "    return list(extract_items_from_outlines(outlines, reader))\n",
    "\n",
    "def extract_items_from_outlines(outlines, reader):\n",
    "    for item in outlines:\n",
    "        if isinstance(item, list):\n",
    "            # Recursive call for nested items\n",
    "            yield from extract_items_from_outlines(item, reader)\n",
    "        else:\n",
    "            yield item, reader\n",
    "def get_page_number(reader, page_obj):\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        if page == page_obj:\n",
    "            return i + 1  # '+ 1' to get 1-based page numbering\n",
    "    return None  # return None if page not found\n",
    "\n",
    "\n",
    "def get_questions(data_text):\n",
    "    questions = []\n",
    "    current_question = []\n",
    "    \n",
    "    for line in data_text.split('\\n'):\n",
    "        if re.match(r\"^\\$\\d+\\$\", line):  # Check if the line starts with a pattern like \"$1$\"\n",
    "            if current_question:  # If there's a current question, append it to the questions list\n",
    "                questions.append(\"\\n\".join(current_question))\n",
    "                current_question = []  # Reset the current question\n",
    "        current_question.append(line)\n",
    "    \n",
    "    # Add the last question if there's any\n",
    "    if current_question:\n",
    "        questions.append(\" \".join(current_question))\n",
    "        \n",
    "    # start_index = 0\n",
    "    # for i in range(len(questions)):\n",
    "    #     if re.match(\".*EXERCISES\\s+\\d+\\.[A-Z]\",questions[i]):\n",
    "    #         exercise_section = re.findall(\"EXERCISES\\s+(\\d+\\.[A-Z])\", questions[i])[0]\n",
    "    #         start_index = i+1\n",
    "    #     #questions[i] = questions[i].replace('\\n',\" \")\n",
    "    #     re.findall(r\"^\\$\\d+\\$\", questions[i])\n",
    "    return questions\n",
    "\n",
    "def to_frame(data,start_page):\n",
    "    exercise_section = None\n",
    "    start_index = 0\n",
    "    for index,line in enumerate(data):\n",
    "        match = re.search(r\"EXERCISES\\s+(\\d+\\.[A-Z])\", line)\n",
    "        if match:\n",
    "            exercise_section = match.group(1)\n",
    "            start_index = index+1\n",
    "    if exercise_section is None:\n",
    "        for index,line in enumerate(data):\n",
    "            match = re.search(r\"EXERCISES\\s+(\\$?\\d+(\\.\\w)?\\$?)\", line)\n",
    "            if match:\n",
    "                exercise_section = match.group(1).replace('$', '') \n",
    "                start_index = index+1\n",
    "    if not exercise_section:\n",
    "        raise ValueError(\"Exercise section not found in data!\")\n",
    "\n",
    "    # Extracting questions\n",
    "    questions = []\n",
    "    question_number = None\n",
    "\n",
    "\n",
    "                \"section\": exercise_section,\n",
    "                \"qnumb\": question_number,\n",
    "                \"question\": line[len(str(question_number))+2:].strip().replace('\\n',\" \") # Question is empty as it's only 1 line long\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(questions)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Extract Questions from Linear Algebra Done Right](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of the pages in the textbook where questions are. This let's us send only the pages we need to the Mathpix API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r'books/2015_Book_LinearAlgebraDoneRight.pdf'\n",
    "outlines = list(extract_outline(pdf_path))\n",
    "page_list = []\n",
    "for index, (item, reader) in enumerate(outlines):\n",
    "    if re.search(r'EXERCISES', item.title, re.IGNORECASE):\n",
    "        \n",
    "        # Check if next section is also EXERCISES\n",
    "        if (index + 1 < len(outlines) and \n",
    "            re.search(r'EXERCISES', outlines[index + 1][0].title, re.IGNORECASE)):\n",
    "            continue  # Skip the current, move to the next\n",
    "        \n",
    "        start_page_obj = item.page.get_object()\n",
    "        start_page_num = get_page_number(reader, start_page_obj)\n",
    "        \n",
    "        # Try to determine the end page based on the next outline item\n",
    "        if index + 1 < len(outlines):\n",
    "            next_item, _ = outlines[index + 1]\n",
    "            end_page_obj = next_item.page.get_object()\n",
    "            end_page_num = get_page_number(reader, end_page_obj) - 1  \n",
    "                \n",
    "        else:\n",
    "            end_page_num = len(reader.pages)  # Last page if it's the last outline item\n",
    "        \n",
    "        # Extract text from the range\n",
    "        print(start_page_num,end_page_num)\n",
    "        page_list.append([start_page_num,end_page_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the list of pages and send them to the Mathpix API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines = list(extract_outline(pdf_path))\n",
    "li = []\n",
    "\n",
    "for i in range(len(page_list)):\n",
    "        start_page = page_list[i][0]\n",
    "        end_page = page_list[i][1]\n",
    "        print(start_page,end_page)\n",
    "        data_result = extract_pages_and_process(pdf_path, start_page, end_page)\n",
    "\n",
    "        data_text = data_result\n",
    "        questions = get_questions(data_text)\n",
    "        temp_df = to_frame(questions,start_page)\n",
    "        li.append(temp_df)\n",
    "        \n",
    "      \n",
    "df = pd.concat(li)\n",
    "df['isbn'] = \"978-3-319-11079-0\" # this is what we are going to use to tie books together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'temp_questions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Calculus Textbook](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still a WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = r'books/calculus-10th-edition-anton.pdf'\n",
    "outlines = list(extract_outline(pdf_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Attempt 1 to get questions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_section = \".*0.2: New Functions from Old.*\"\n",
    "end_pattern = r\"EXERCISE SET \\d+\\.\\d+\"\n",
    "end_pattern_space =  r\"EXERCISE SET \\d+\\ .\\d+\"\n",
    "end_pattern_chapter = r\"CHAPTER \\d+\\ REVIEW EXERCISES\"\n",
    "\n",
    "# Store questions\n",
    "questions = []\n",
    "\n",
    "# Flag to start extraction\n",
    "start_extraction = False\n",
    "\n",
    "with open(pdf_path, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    for i,page in enumerate(reader.pages):\n",
    "        \n",
    "        text = page.extract_text()\n",
    "        if i == 33:break\n",
    "        if start_extraction:\n",
    "            # Check for ending section\n",
    "            if re.search(end_pattern, text):\n",
    "                break\n",
    "            # Extract questions from this page\n",
    "            # (You might need some pattern or logic to correctly split or identify individual questions)\n",
    "            questions.append(text) \n",
    "        elif start_section in text:\n",
    "            re.search(start_section,text)\n",
    "            start_extraction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Attempt 2](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more complicated. I don't remember exactly how it works.\n",
    "\n",
    "Start by getting the page lists again. The book doesn't have the same consitent format, so we have to have way more checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_list = []\n",
    "outlines = list(extract_outline(pdf_path))\n",
    "outlines = outlines[12:-7]\n",
    "last_start_page = 0\n",
    "with open(pdf_path, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    for index, (item, reader) in enumerate(outlines):\n",
    "        start_page_obj = item.page.get_object()\n",
    "        start_page_num = get_page_number(reader, start_page_obj)\n",
    "        \n",
    "        # Try to determine the end page based on the next outline item\n",
    "        if index + 1 < len(outlines):\n",
    "            next_item, _ = outlines[index + 1]\n",
    "            end_page_obj = next_item.page.get_object()\n",
    "            end_page_num = get_page_number(reader, end_page_obj) - 1  \n",
    "        if end_page_num < start_page_num:\n",
    "            print('start > end')\n",
    "            end_page_num = start_page_num\n",
    "        print(item.title,start_page_num,end_page_num)\n",
    "        # work backwards from end_page\n",
    "        current_page = end_page_num\n",
    "        exercise=None\n",
    "        while True: \n",
    "            text = reader.pages[current_page].extract_text()\n",
    "            if re.search(end_pattern, text):\n",
    "                exercise = re.search(end_pattern,text).group(0)\n",
    "                exercise = exercise.replace('EXERCISE SET ','').strip()\n",
    "                break\n",
    "            elif re.search(end_pattern_chapter, text):\n",
    "                exercise = re.search(end_pattern_chapter,text).group(0)\n",
    "                exercise = exercise.replace('REVIEW EXERCISES ','').strip()\n",
    "                exercise = exercise.replace('CHAPTER','').strip()\n",
    "                break\n",
    "            elif re.search(end_pattern_space, text):\n",
    "                exercise = re.search(end_pattern_space,text).group(0)\n",
    "                exercise = exercise.replace('EXERCISE SET ','').strip()\n",
    "                exercise = exercise.replace(' ','')\n",
    "                break\n",
    "            current_page-=1\n",
    "        if not current_page == last_start_page:\n",
    "            page_list.append([current_page,end_page_num,exercise])\n",
    "        else:\n",
    "            print('skipping page',current_page)\n",
    "        last_start_page = current_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the page lists to grab get the data from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_questions_calc(data_text):\n",
    "    questions = []\n",
    "    current_question = []\n",
    "    pattern = r'(\\b\\d+)-(\\d+)\\b'\n",
    "    \n",
    "\n",
    "    for line in data_text.split('\\n'):\n",
    "        if re.match(r\"\\b\\d+\\.\\s\", line):  # Check if the line starts with a pattern like \"$1$\"\n",
    "            if current_question:  # If there's a current question, append it to the questions list\n",
    "                questions.append(\"\\n\".join(current_question))\n",
    "                current_question = []  # Reset the current question\n",
    "        if re.match(pattern, line):\n",
    "            if current_question:\n",
    "                questions.append(\"\\n\".join(current_question))\n",
    "                current_question = []  # Reset the current question\n",
    "        current_question.append(line)\n",
    "    \n",
    "    # Add the last question if there's any\n",
    "    if current_question:\n",
    "        questions.append(\" \".join(current_question))\n",
    "  \n",
    "    return questions\n",
    "\n",
    "def process_data(data):\n",
    "    descriptor = None  # Holds the extra descriptor for a range of questions\n",
    "    output = []\n",
    "\n",
    "    for item in data:\n",
    "        range_match = re.match(r'(\\d+)-(\\d+) (.+)', item)\n",
    "        question_match = re.match(r'(\\d+)\\. (.+)', item)\n",
    "\n",
    "        if range_match:\n",
    "            start, end, descriptor_text = range_match.groups()\n",
    "            descriptor = (int(start), int(end), descriptor_text)\n",
    "        elif question_match and descriptor:\n",
    "            q_num, q_text = question_match.groups()\n",
    "            q_num = int(q_num)\n",
    "\n",
    "            if descriptor[0] <= q_num <= descriptor[1]:\n",
    "                full_question = f\"{q_num}. {descriptor[2]} {q_text}\"\n",
    "                output.append(full_question)\n",
    "            else:\n",
    "                # If the question number is not in the range of the descriptor, we reset the descriptor\n",
    "                output.append(item)\n",
    "                if q_num > descriptor[1]:\n",
    "                    descriptor = None\n",
    "        else:\n",
    "            output.append(item)\n",
    "\n",
    "    return output\n",
    "q = get_questions_calc(data_text)\n",
    "a = process_data(q)\n",
    "\n",
    "li = []\n",
    "\n",
    "for i in range(len(page_list)):\n",
    "        start_page = page_list[i][0]\n",
    "        end_page = page_list[i][1]\n",
    "        exercise = page_list[i][2]\n",
    "        print(start_page,end_page)\n",
    "        data_text = extract_pages_and_process(pdf_path, start_page, end_page)\n",
    "        \n",
    "        questions = get_questions_calc(data_text)\n",
    "        processed_data = process_data(questions)\n",
    "        temp_df = to_frame(processed_data,start_page)\n",
    "        li.append(temp_df)\n",
    "\n",
    "df = pd.concat(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
